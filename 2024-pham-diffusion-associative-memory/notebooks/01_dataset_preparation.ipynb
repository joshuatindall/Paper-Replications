{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1Ymj9-QZC3jaaEadACN4a_nQ6LL-rsM3x","authorship_tag":"ABX9TyPG92/q1MKIXNylll+ncToq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pFoEOgCM0KMT","executionInfo":{"status":"ok","timestamp":1742427997127,"user_tz":240,"elapsed":18,"user":{"displayName":"Joshua Tindall","userId":"06605102023665237550"}},"outputId":"16a0ca10-3eb0-4ffe-8bc8-b05a8a1f2a36"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Paper-Replications/Memorization-to-generalization\n"]}],"source":["%cd /content/drive/MyDrive/Paper-Replications/Memorization-to-generalization"]},{"cell_type":"code","source":["import os\n","import sys\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","import pickle\n","from IPython.display import display, HTML\n","\n","# Add the project root to the path\n","project_root = '../..'\n","sys.path.append(project_root)\n","\n","# Import our dataset utilities\n","from src.data.datasets import generate_dataset_splits, load_dataset_split, load_base_dataset"],"metadata":{"id":"YdF6vL233oka","executionInfo":{"status":"ok","timestamp":1742429201897,"user_tz":240,"elapsed":9317,"user":{"displayName":"Joshua Tindall","userId":"06605102023665237550"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["datasets = ['mnist', 'fashion_mnist', 'cifar10']\n","num_splits = 38\n","seed = 42\n","save_dir = './data/splits'\n","\n","for dataset_name in datasets:\n","    print(f\"Generating splits for {dataset_name}...\")\n","    splits_info = generate_dataset_splits(\n","        dataset_name,\n","        num_splits=num_splits,\n","        seed=seed,\n","        save_dir=save_dir\n","    )"],"metadata":{"id":"_2oC9bOBBkR1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(12, 6))\n","for dataset_name in datasets:\n","    # Load split info\n","    with open(os.path.join(save_dir, dataset_name, \"splits_info.pkl\"), 'rb') as f:\n","        splits_info = pickle.load(f)\n","\n","    # Extract split sizes\n","    sizes = [info['size'] for info in splits_info]\n","\n","    # Plot on log scale\n","    plt.plot(range(1, len(sizes) + 1), sizes, 'o-', label=dataset_name)\n","\n","plt.xlabel('Split Index')\n","plt.ylabel('Number of Training Samples')\n","plt.title('Dataset Split Sizes')\n","plt.grid(True, which='both', linestyle='--', alpha=0.7)\n","plt.yscale('log')\n","plt.legend()\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"XWDEAsXP3QOx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def show_samples(dataset, indices, title, n_cols=10):\n","    n_samples = len(indices)\n","    n_rows = (n_samples + n_cols - 1) // n_cols\n","\n","    fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols*1.5, n_rows*1.5))\n","    axes = axes.flatten()\n","\n","    for i, idx in enumerate(indices):\n","        img, label = dataset[idx]\n","        if isinstance(img, torch.Tensor):\n","            img = img.permute(1, 2, 0).numpy()\n","\n","        # Handle different channels\n","        if img.shape[2] == 1:  # Grayscale\n","            img = img.squeeze()\n","            axes[i].imshow(img, cmap='gray')\n","        else:  # RGB\n","            # Denormalize\n","            if dataset_name == 'cifar10':\n","                mean = np.array([0.4914, 0.4822, 0.4465])\n","                std = np.array([0.2470, 0.2435, 0.2616])\n","                img = img * std + mean\n","                img = np.clip(img, 0, 1)\n","\n","            axes[i].imshow(img)\n","\n","        axes[i].set_title(f\"#{idx}: {label}\")\n","        axes[i].axis('off')\n","\n","    # Hide unused subplots\n","    for i in range(n_samples, len(axes)):\n","        axes[i].axis('off')\n","\n","    plt.suptitle(title, fontsize=16)\n","    plt.tight_layout()\n","    plt.show()\n","\n","# Select a few key split sizes to visualize\n","splits_to_show = [1, 5, 10, 20]  # Corresponds to splits with indices 1, 5, 10, 20\n","\n","dataset_name = 'mnist'  # Change to visualize different datasets\n","for split_idx in splits_to_show:\n","    # Load the dataset split\n","    train_subset, _ = load_dataset_split(dataset_name, split_idx)\n","\n","    # For the subset, we need to get the actual indices\n","    indices = train_subset.indices[:20]  # Show at most 20 samples\n","\n","    # Get the base dataset to access the actual samples\n","    base_dataset, _ = load_base_dataset(dataset_name)\n","\n","    # Show samples from this split\n","    show_samples(\n","        base_dataset,\n","        indices,\n","        f\"{dataset_name} - Split {split_idx} (Size: {len(train_subset)} samples)\"\n","    )"],"metadata":{"id":"V7le8CZ-BtGx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset_name = 'mnist'  # Change to visualize different datasets\n","\n","# Load the full dataset\n","full_dataset, _ = load_base_dataset(dataset_name)\n","\n","# Check label distribution for each split\n","label_distributions = []\n","split_sizes = []\n","\n","for split_idx in range(1, num_splits + 1):\n","    train_subset, _ = load_dataset_split(dataset_name, split_idx)\n","    split_sizes.append(len(train_subset))\n","\n","    # Count labels\n","    labels = [full_dataset[idx][1] for idx in train_subset.indices]\n","    unique_labels, counts = np.unique(labels, return_counts=True)\n","\n","    # Create a distribution with all classes\n","    distribution = np.zeros(10)  # Assuming 10 classes\n","    distribution[unique_labels] = counts\n","\n","    label_distributions.append(distribution)\n","\n","# Convert to percentage\n","label_distributions_percent = [dist / sum(dist) * 100 for dist in label_distributions]\n","\n","# Plot the label distribution for selected splits\n","plt.figure(figsize=(14, 8))\n","\n","splits_to_plot = [0, 9, 19, 29, -1]  # First, a few middle ones, and last split\n","for i, split_idx in enumerate(splits_to_plot):\n","    plt.subplot(len(splits_to_plot), 1, i+1)\n","    plt.bar(range(10), label_distributions_percent[split_idx])\n","    plt.title(f\"Split {split_idx+1} (Size: {split_sizes[split_idx]} samples)\")\n","    plt.xlabel('Class')\n","    plt.ylabel('Percentage')\n","    plt.xticks(range(10))\n","    plt.ylim(0, 50)  # Limit to better see variations\n","\n","plt.tight_layout()\n","plt.show()\n","\n","# Print summary statistics\n","print(\"Dataset splits summary:\")\n","for dataset_name in datasets:\n","    with open(os.path.join(save_dir, dataset_name, \"splits_info.pkl\"), 'rb') as f:\n","        splits_info = pickle.load(f)\n","\n","    sizes = [info['size'] for info in splits_info]\n","\n","    print(f\"\\n{dataset_name}:\")\n","    print(f\"  Number of splits: {len(sizes)}\")\n","    print(f\"  Smallest split (split 1): {sizes[0]} samples\")\n","    print(f\"  Largest split (split {len(sizes)}): {sizes[-1]} samples\")\n","\n","    # Print some intermediate split sizes\n","    indices = [0, 4, 9, 19, 29, -1]\n","    print(f\"  Selected split sizes:\")\n","    for idx in indices:\n","        if idx == -1:\n","            split_num = len(sizes)\n","        else:\n","            split_num = idx + 1\n","        print(f\"    Split {split_num}: {sizes[idx]} samples\")"],"metadata":{"id":"5HkwkXeoBwgV"},"execution_count":null,"outputs":[]}]}